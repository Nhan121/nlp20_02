{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"D://Nhan project 2019-2020//NLP//Project//train.csv\", usecols = [\"text\", \"target\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_names : \\ttext', 'col_names : \\ttarget'], dtype='object')\n",
      "\n",
      "\n",
      "Data-dimensions: \t(7613, 2)\n",
      "\n",
      "\n",
      "Count the not-null values of each features: \n",
      "text      7613\n",
      "target    7613\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"col_names : \\t\" + df.columns)\n",
    "print('\\n')\n",
    "print(\"Data-dimensions: \\t\" + str(df.shape))\n",
    "print('\\n')\n",
    "print(\"Count the not-null values of each features: \\n\" + str(df.notnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dimension after checking duplicate & removing is:\t(7521, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "print(\"The new dimension after checking duplicate & removing is:\\t\" + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>Numb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  Text_length  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1           69   \n",
       "1             Forest fire near La Ronge Sask. Canada       1           38   \n",
       "2  All residents asked to 'shelter in place' are ...       1          133   \n",
       "3  13,000 people receive #wildfires evacuation or...       1           65   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1           88   \n",
       "\n",
       "   Numb_words  \n",
       "0          13  \n",
       "1           7  \n",
       "2          22  \n",
       "3           8  \n",
       "4          16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_length'] = df['text'].str.len()\n",
    "df['Numb_words'] = df['text'].str.split().map(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker    \n",
    "\n",
    "def process_text(str_input):\n",
    "    ## 1. Remove url_link\n",
    "    remove_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', str_input)\n",
    "    \n",
    "    ## 2. Remove html_link\n",
    "    remove_html = re.compile(r'<.*?>').sub(r'', remove_url)\n",
    "    \n",
    "    ## 3. Remove Emojis\n",
    "    remove_emo = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE).sub(r'', remove_html)\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", remove_emo).lower().split()    \n",
    "        \n",
    "    ## 4. spell_correction\n",
    "    # spell = SpellChecker()\n",
    "    # words = [spell.correction(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_process = CountVectorizer(analyzer = process_text).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target.to_numpy()\n",
    "X = df[['text', 'Text_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=310.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 2 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 3 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 4 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 5 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 6 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 7 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 8 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 9 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 10 - Current best internal CV score: 0.7845765674029299\n",
      "Generation 11 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 12 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 13 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 14 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 15 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 16 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 17 - Current best internal CV score: 0.7927460559906695\n",
      "Generation 18 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 19 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 20 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 21 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 22 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 23 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 24 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 25 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 26 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 27 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 28 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 29 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 30 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 31 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 32 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 33 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 34 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 35 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 36 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 37 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 38 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 39 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 40 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 41 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 42 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 43 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 44 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 45 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 46 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 47 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 48 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 49 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 50 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 51 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 52 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 53 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 54 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 55 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 56 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 57 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 58 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 59 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 60 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 61 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 62 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 63 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 64 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 65 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 66 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 67 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 68 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 69 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 70 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 71 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 72 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 73 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 74 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 75 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 76 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 77 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 78 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 79 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 80 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 81 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 82 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 83 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 84 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 85 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 86 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 87 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 88 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 89 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 90 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 91 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 92 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 93 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 94 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 95 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 96 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 97 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 98 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 99 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 100 - Current best internal CV score: 0.8033843192905297\n",
      "\n",
      "Best pipeline: BernoulliNB(SelectPercentile(input_matrix, percentile=97), alpha=1.0, fit_prior=False)\n",
      "0.7948604342046965\n",
      "Fit&trainning time :  32114.64671087265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Set test_size = 0.3\n",
    "test_size = 0.3\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify = y, random_state = 42)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = process_text)\n",
    "\n",
    "tfidf_train = tfidf_vect.fit(X_train['text']).transform(X_train['text']) \n",
    "tfidf_test = tfidf_vect.fit(X_train['text']).transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([\n",
    "                            X_train[['Text_length']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_train.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "X_test_vect = pd.concat([\n",
    "                            X_test[['Text_length']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "tpot_clf = TPOTClassifier(generations=100, population_size=10, offspring_size=3 , cv=5,\n",
    "                          verbosity=2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test_vect, y_test))\n",
    "print ('Fit&trainning time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hence, the best method is using the Pipeline belong with BernoulliNB and SelectPercentile.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1.**`First, we only focus on the BernoulliNB (without using Pipeline)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB(fit_prior=False)\n",
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the confusion_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.67%\n",
      "Testing_Accuracy: 80.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1303\n",
      "           1       0.83      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.81      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1167  136]\n",
      " [ 300  681]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using F-measure in the `confusion matrix`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1167, 300, 136)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure = 84.26%.\n"
     ]
    }
   ],
   "source": [
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2. Now, I try to add one more feature: `Number of words` to this model. Let see the F_measure in the confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.67%\n",
      "Testing_Accuracy: 80.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1303\n",
      "           1       0.83      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.81      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1167  136]\n",
      " [ 300  681]]\n",
      "F-measure = 84.26%.\n"
     ]
    }
   ],
   "source": [
    "y = df.target.to_numpy()\n",
    "X = df[['text', 'Text_length', 'Numb_words']]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Set test_size = 0.3\n",
    "test_size = 0.3\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify = y, random_state = 42)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = process_text)\n",
    "\n",
    "tfidf_train = tfidf_vect.fit(X_train['text']).transform(X_train['text']) \n",
    "tfidf_test = tfidf_vect.fit(X_train['text']).transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([\n",
    "                            X_train[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_train.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "X_test_vect = pd.concat([\n",
    "                            X_test[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "clf = BernoulliNB(alpha = 1.0, fit_prior=False)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))\n",
    "\n",
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "\n",
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the `F_measure = 84.26` and there are nothing change!!\n",
    "\n",
    "**Approach 3. Finally, we use the Pipeline and BernoulliBN and SelectPercentile.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                                    score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "                             binarize=0.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf',  BernoulliNB(SelectPercentile(percentile = 97)))\n",
    "                   ])\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List the names in `pipeline` with `.named_steps`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                    score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "             binarize=0.0, class_prior=None, fit_prior=True)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the statement in `clf`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                   score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "            binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the params `alpha` and `fit_prior` into BernoulliNB()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['clf'].set_params(alpha=1.0, fit_prior=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verify the parameters in pipeline***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.50%\n",
      "Testing_Accuracy: 81.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84      1303\n",
      "           1       0.84      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.82      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1172  131]\n",
      " [ 304  677]]\n",
      "F-measure = 84.35%.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))\n",
    "\n",
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "\n",
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
